{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## # Introduction\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_1010/img/book_cover.jpg\" alt=\"The book cover of Peter and Wendy\" style=\"width:183;height:253px;\"></p>\n",
    "<h3 id=\"flyawaywithpeterpan\">Fly away with Peter Pan!</h3>\n",
    "<p>Peter Pan has been the companion of many children, and went a long way, starting as a Christmas play and ending up as a Disney classic. Did you know that although the play was titled \"Peter Pan, Or The Boy Who Wouldn't Grow Up\", J. M. Barrie's novel was actually titled \"Peter and Wendy\"? </p>\n",
    "<p>You're going to explore and analyze Peter Pan's text to answer the question in the instruction pane below. You are working with the text version available here at <a href=\"https://www.gutenberg.org/files/16/16-h/16-h.htm\">Project Gutenberg</a>. Feel free to add as many cells as necessary. Finally, remember that you are only tested on your answer, not on the methods you use to arrive at the answer!</p>\n",
    "<p><strong>Note:</strong> If you haven't completed a DataCamp project before you should check out the <a href=\"https://projects.datacamp.com/projects/33\">Intro to Projects</a> first to learn about the interface. <a href=\"https://www.datacamp.com/courses/intermediate-importing-data-in-python\">Intermediate Importing Data in Python</a> and <a href=\"https://www.datacamp.com/courses/introduction-to-natural-language-processing-in-python\">Introduction to Natural Language Processing in Python</a> teach the skills required to complete this project. Should you decide to use them, English stopwords have been downloaded from <code>nltk</code> and are available for you in your environment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Use this cell to begin your analysis, and add as many as you would like!\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from collections import Counter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get('https://www.gutenberg.org/files/16/16-h/16-h.htm')\n",
    "r.encoding = 'utf-8'\n",
    "#r.status_code\n",
    "html_doc = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function of the cell above is to fetch the \"Fly away with peter Pan\" htm file from the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " be tied up\r\n",
      "this instant.”\r\n",
      "\n",
      "\r\n",
      "“George, George,” Mrs. Darling whispered, “remember what I\r\n",
      "told you about that boy.”\r\n",
      "\n",
      "\r\n",
      "Alas, he would not listen. He was determined to show who was master in that\r\n",
      "house, and when commands would not draw Nana from the kennel, he lured her out\r\n",
      "of it with honeyed words, and seizing her roughly, dragged her from the\r\n",
      "nursery. He was ashamed of himself, and yet he did it. It was all owing to his\r\n",
      "too affectionate nature, which craved for admiration. When he had tied her up\r\n",
      "in the back-yard, the wretched father went and sat in the passage, with his\r\n",
      "knuckles to his eyes.\r\n",
      "\n",
      "\r\n",
      "In the meantime Mrs. Darling had put the children to bed in unwonted silence\r\n",
      "and lit their night-lights. They could hear Nana barking, and John whimpered,\r\n",
      "“It is because he is chaining her up in the yard,” but Wendy was\r\n",
      "wiser.\r\n",
      "\n",
      "\r\n",
      "“That is not Nana’s unhappy bark,” she said, little guessing\r\n",
      "what was about to happen; “that is her bark when she smells\r\n",
      "danger.”\r\n",
      "\n",
      "\r\n",
      "Danger!\r\n",
      "\n",
      "\r\n",
      "“Are\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "html_text = soup.get_text()\n",
    "\n",
    "print(html_text[32000:33000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Beautiful Soup object is used to extract text from the html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Peter', 'Pan', 'by', 'James', 'M', 'Barrie']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "tokens = tokenizer.tokenize(html_text)\n",
    "\n",
    "print(tokens[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RegexpTokenizer is used to filter out unwanted stuff such as whitespace, punctuation e.t.c from the text by removing everything that isn't a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'peter', 'pan', 'by', 'james', 'm', 'barrie']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "for word in tokens:\n",
    "    word_lowercase = word.lower()\n",
    "    words.append(word_lowercase)\n",
    "    \n",
    "print(words[:11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other to find the common words, we need to make sure that all words are in the case(lowercase) so the computer can identify that \"OR\" is the same as \"or\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "stopWords = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented stopwords so as filter out unnecessary words from our list of words such as \"the\", \"of\",\" a\" and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['project', 'gutenberg', 'ebook', 'peter', 'pan', 'james', 'barrie', 'body', 'margin', 'left', '20']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "New_words = []\n",
    "\n",
    "for the_word in words:\n",
    "    if the_word not in stopWords:\n",
    "        New_words.append(the_word)\n",
    "    \n",
    "print(New_words[:11])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes stopWords from the list of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('peter', 409), ('wendy', 362), ('said', 358), ('would', 217), ('one', 212), ('hook', 174), ('could', 142), ('cried', 136), ('john', 133), ('time', 126)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NumOfWords = Counter(New_words)\n",
    "\n",
    "TopTen = NumOfWords.most_common(10)\n",
    "\n",
    "print(TopTen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the most frequent words in \"Fly away with Peter Pan!\" are shown above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['peter', 'wendy', 'john']\n"
     ]
    }
   ],
   "source": [
    "convDict = dict(TopTen)\n",
    "newlist = []\n",
    "\n",
    "for key in convDict.keys():\n",
    "    \n",
    "    newlist.append(key)\n",
    "\n",
    "protagonists = ['peter', 'wendy', 'john']\n",
    "\n",
    "print(protagonists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 'peter', 'wendy', 'john' seems to be the only name of person from the topten most frequent words, we can assume that 'peter', 'wendy', 'john' are the protagonists in the book "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
